{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1 explore data\n",
    "\n",
    "customer_churn = pd.read_csv('Telco-Customer-Churn.csv')\n",
    "print(customer_churn.head())\n",
    "# Display summary statistics\n",
    "print(customer_churn.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1 Clean data\n",
    "def load_data():\n",
    "    # Load the data\n",
    "    telco = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    telco.drop(columns=['customerID', 'PaymentMethod'], inplace=True)\n",
    "\n",
    "    # Filter rows\n",
    "    telco = telco[(telco['InternetService'] != \"No\") & (telco['PhoneService'] != \"No\")]\n",
    "\n",
    "    # Reset index to clean up levels after filtering\n",
    "    telco.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Drop additional columns\n",
    "    telco.drop(columns=['PhoneService', 'TotalCharges'], inplace=True)\n",
    "\n",
    "    telco['SeniorCitizen'] = telco['SeniorCitizen'].apply(lambda x: 'True' if x == 1 else 'False')\n",
    "\n",
    "    # Convert object columns to categorical\n",
    "    for col in telco.select_dtypes(include='object').columns:\n",
    "        telco[col] = telco[col].astype('category')\n",
    "\n",
    "    # Perform one-hot encoding, dropping the first category in each variable\n",
    "    telco_encoded = pd.get_dummies(telco, drop_first=True)\n",
    "\n",
    "    return telco_encoded\n",
    "\n",
    "# Load the data\n",
    "telco = load_data()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(telco.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(telco.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1a\n",
    "# Filter rows where 'Churn' is 'Yes'\n",
    "Churned = telco[telco['Churn_Yes'] == True]\n",
    "\n",
    "# Calculate the average monthly charges for the resulting 'Churned' DataFrame\n",
    "average_monthly_charges = Churned['MonthlyCharges'].mean()\n",
    "\n",
    "# Print the average monthly charges\n",
    "print(f\"Average Monthly Charges for Churned Customers: ${round(average_monthly_charges,2)}\")\n",
    "\n",
    "# Assume a 12.5% profit margin\n",
    "profit_margin = 0.125\n",
    "\n",
    "# Calculate the expected cost of losing one customer (Cost 1)\n",
    "cost_1 = average_monthly_charges * profit_margin\n",
    "\n",
    "# Print the expected cost of losing one customer\n",
    "print(f\"Expected Cost of Losing One Customer (Cost 1): ${round(cost_1,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob 1b\n",
    "current_customer = telco[telco['Churn_Yes'] == False]\n",
    "\n",
    "# Calculate the average monthly charges for the resulting 'current customers' DataFrame\n",
    "current_customer_average_monthly_charges = current_customer['MonthlyCharges'].mean()\n",
    "\n",
    "# Print the average monthly charges\n",
    "print(f\"Average Monthly Charges for current Customers: ${round(current_customer_average_monthly_charges,2)}\")\n",
    "\n",
    "# Assume a 12.5% profit margin\n",
    "profit_margin_retained_customers = 0.075\n",
    "\n",
    "# Calculate the expected cost of losing one customer (Cost 1)\n",
    "cost_2 = current_customer_average_monthly_charges * profit_margin_retained_customers\n",
    "\n",
    "# Print the expected cost of losing one customer\n",
    "print(f\"Expected Cost of Losing One Customer (Cost 2): ${round(cost_2,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1c\n",
    "\n",
    "# Convert boolean columns to integers (0 and 1)\n",
    "bool_columns = telco.select_dtypes(include=['bool']).columns\n",
    "telco[bool_columns] = telco[bool_columns].astype(int)\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X = telco.drop(columns=['Churn_Yes'])  # Predictor variables (all columns except 'Churn')\n",
    "y = telco['Churn_Yes']  # Response variable\n",
    "\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X_with_intercept).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(logit_model.summary())\n",
    "\n",
    "ypred = (logit_model.predict(X_with_intercept) > 0.5)\n",
    "\n",
    "# Calculate false negatives (FN) and false positives (FP)\n",
    "FN = ((y == True) & (ypred == False)).sum()\n",
    "FP = ((y == False) & (ypred == True)).sum()\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, ypred)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['True Neg-', 'True Pos+'], columns=['Pred Neg-', 'Pred Pos+'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Loss=Cost 1∗FN+Cost 2∗FP\n",
    "# I disagree with Cost 2. It should be 5%, since that is the lost revenue due to the unecessary discount. 7.5% is the profit margin of the retain customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1d\n",
    "def calculate_loss(y_pred_i, y):\n",
    "    FN = ((y == True) & (y_pred_i == False)).sum()\n",
    "    FP = ((y == False) & (y_pred_i == True)).sum()\n",
    "    return cost_1*FN + cost_2*FP\n",
    "\n",
    "# Calculate loss for 1000 evenly distributed thresholds\n",
    "thresholds = np.arange(0.0, 1.0, .001)\n",
    "losses = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_i = (logit_model.predict(X_with_intercept) > threshold)\n",
    "    loss = calculate_loss(y_pred_i, y)\n",
    "    losses.append(loss)\n",
    "\n",
    "print(losses)\n",
    "# Find the optimal threshold\n",
    "optimal_threshold = thresholds[np.argmin(losses)]\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "\n",
    "# Plot the loss with respect to the threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, losses, marker='o', markersize=2)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Loss (FN + FP)')\n",
    "plt.title('Loss with Respect to Threshold')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4 import libaries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 4 explore data\n",
    "\n",
    "letters = pd.read_csv('letters-2.csv')\n",
    "print(letters.head())\n",
    "# Display summary statistics\n",
    "print(letters.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a\n",
    "# Split data\n",
    "letters_shuffled = letters.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_size = int(0.75 * len(letters_shuffled))\n",
    "train_set = letters_shuffled[:train_size]\n",
    "test_set = letters_shuffled[train_size:]\n",
    "\n",
    "# Display the sizes of the training and testing sets\n",
    "print(f\"Training set size: {train_set.shape[0]}\")\n",
    "print(f\"Testing set size: {test_set.shape[0]}\")\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X_train = train_set.drop(columns=['lettr'])  # Predictor variables (all columns except 'lettr')\n",
    "y_train = train_set['lettr']  # Response variable\n",
    "\n",
    "# Add a constant to the predictor variable (intercept term)\n",
    "X_train_with_intercept = sm.add_constant(X_train)\n",
    "print(X_train_with_intercept.head())\n",
    "print(\"---\")\n",
    "print(y_train.head())\n",
    "\n",
    "# Standardize the predictor variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Print the summary of the model\n",
    "try:\n",
    "    #multinomial_reg = sm.MNLogit(y_train, X_train_scaled).fit()\n",
    "    # Print the summary of the model\n",
    "    #print(multinomial_reg.summary())\n",
    "except Exception as e:\n",
    "   #print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1 explore data\n",
    "\n",
    "customer_churn = pd.read_csv('Telco-Customer-Churn.csv')\n",
    "print(customer_churn.head())\n",
    "# Display summary statistics\n",
    "print(customer_churn.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1 Clean data\n",
    "def load_data():\n",
    "    # Load the data\n",
    "    telco = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    telco.drop(columns=['customerID', 'PaymentMethod'], inplace=True)\n",
    "\n",
    "    # Filter rows\n",
    "    telco = telco[(telco['InternetService'] != \"No\") & (telco['PhoneService'] != \"No\")]\n",
    "\n",
    "    # Reset index to clean up levels after filtering\n",
    "    telco.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Drop additional columns\n",
    "    telco.drop(columns=['PhoneService', 'TotalCharges'], inplace=True)\n",
    "\n",
    "    telco['SeniorCitizen'] = telco['SeniorCitizen'].apply(lambda x: 'True' if x == 1 else 'False')\n",
    "\n",
    "    # Convert object columns to categorical\n",
    "    for col in telco.select_dtypes(include='object').columns:\n",
    "        telco[col] = telco[col].astype('category')\n",
    "\n",
    "    # Perform one-hot encoding, dropping the first category in each variable\n",
    "    telco_encoded = pd.get_dummies(telco, drop_first=True)\n",
    "\n",
    "    return telco_encoded\n",
    "\n",
    "# Load the data\n",
    "telco = load_data()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(telco.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(telco.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1a\n",
    "# Filter rows where 'Churn' is 'Yes'\n",
    "Churned = telco[telco['Churn_Yes'] == True]\n",
    "\n",
    "# Calculate the average monthly charges for the resulting 'Churned' DataFrame\n",
    "average_monthly_charges = Churned['MonthlyCharges'].mean()\n",
    "\n",
    "# Print the average monthly charges\n",
    "print(f\"Average Monthly Charges for Churned Customers: ${round(average_monthly_charges,2)}\")\n",
    "\n",
    "# Assume a 12.5% profit margin\n",
    "profit_margin = 0.125\n",
    "\n",
    "# Calculate the expected cost of losing one customer (Cost 1)\n",
    "cost_1 = average_monthly_charges * profit_margin\n",
    "\n",
    "# Print the expected cost of losing one customer\n",
    "print(f\"Expected Cost of Losing One Customer (Cost 1): ${round(cost_1,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob 1b\n",
    "current_customer = telco[telco['Churn_Yes'] == False]\n",
    "\n",
    "# Calculate the average monthly charges for the resulting 'current customers' DataFrame\n",
    "current_customer_average_monthly_charges = current_customer['MonthlyCharges'].mean()\n",
    "\n",
    "# Print the average monthly charges\n",
    "print(f\"Average Monthly Charges for current Customers: ${round(current_customer_average_monthly_charges,2)}\")\n",
    "\n",
    "# Assume a 12.5% profit margin\n",
    "profit_margin_retained_customers = 0.075\n",
    "\n",
    "# Calculate the expected cost of losing one customer (Cost 1)\n",
    "cost_2 = current_customer_average_monthly_charges * profit_margin_retained_customers\n",
    "\n",
    "# Print the expected cost of losing one customer\n",
    "print(f\"Expected Cost of Losing One Customer (Cost 2): ${round(cost_2,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              Churn_Yes   No. Observations:                 4835\n",
      "Model:                            GLM   Df Residuals:                     4817\n",
      "Model Family:                Binomial   Df Model:                           17\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2328.9\n",
      "Date:                Thu, 21 Nov 2024   Deviance:                       4657.8\n",
      "Time:                        22:46:58   Pearson chi2:                 5.08e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.2608\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                           0.6915      1.498      0.462      0.644      -2.244       3.627\n",
      "tenure                         -0.0357      0.003    -13.806      0.000      -0.041      -0.031\n",
      "MonthlyCharges                 -0.0285      0.033     -0.858      0.391      -0.093       0.037\n",
      "gender_Male                    -0.0403      0.072     -0.559      0.576      -0.181       0.101\n",
      "SeniorCitizen_True              0.2102      0.090      2.342      0.019       0.034       0.386\n",
      "Partner_Yes                    -0.0483      0.085     -0.568      0.570      -0.215       0.118\n",
      "Dependents_Yes                 -0.0715      0.100     -0.715      0.475      -0.267       0.124\n",
      "MultipleLines_Yes               0.4799      0.185      2.593      0.010       0.117       0.843\n",
      "InternetService_Fiber optic     1.7121      0.834      2.052      0.040       0.077       3.348\n",
      "OnlineSecurity_Yes             -0.2402      0.188     -1.275      0.202      -0.609       0.129\n",
      "OnlineBackup_Yes               -0.0002      0.184     -0.001      0.999      -0.360       0.360\n",
      "DeviceProtection_Yes            0.1079      0.185      0.582      0.561      -0.256       0.471\n",
      "TechSupport_Yes                -0.1959      0.189     -1.036      0.300      -0.567       0.175\n",
      "StreamingTV_Yes                 0.5501      0.341      1.612      0.107      -0.119       1.219\n",
      "StreamingMovies_Yes             0.5484      0.342      1.603      0.109      -0.122       1.219\n",
      "Contract_One year              -0.5287      0.120     -4.407      0.000      -0.764      -0.294\n",
      "Contract_Two year              -1.1417      0.197     -5.795      0.000      -1.528      -0.756\n",
      "PaperlessBilling_Yes            0.3375      0.084      4.020      0.000       0.173       0.502\n",
      "===============================================================================================\n",
      "           Pred Neg-  Pred Pos+\n",
      "True Neg-       2770        479\n",
      "True Pos+        651        935\n"
     ]
    }
   ],
   "source": [
    "# Prob 1c\n",
    "\n",
    "# Convert boolean columns to integers (0 and 1)\n",
    "bool_columns = telco.select_dtypes(include=['bool']).columns\n",
    "telco[bool_columns] = telco[bool_columns].astype(int)\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X = telco.drop(columns=['Churn_Yes'])  # Predictor variables (all columns except 'Churn')\n",
    "y = telco['Churn_Yes']  # Response variable\n",
    "\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.GLM(y, X_with_intercept, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(logit_model.summary())\n",
    "\n",
    "ypred = (logit_model.predict(X_with_intercept) > 0.5)\n",
    "\n",
    "# Calculate false negatives (FN) and false positives (FP)\n",
    "FN = ((y == True) & (ypred == False)).sum()\n",
    "FP = ((y == False) & (ypred == True)).sum()\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, ypred)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['True Neg-', 'True Pos+'], columns=['Pred Neg-', 'Pred Pos+'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Loss=Cost 1∗FN+Cost 2∗FP\n",
    "# I disagree with Cost 2. It should be 5%, since that is the lost revenue due to the unecessary discount. 7.5% is the profit margin of the retain customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 1d\n",
    "def calculate_loss(y_pred_i, y):\n",
    "    FN = ((y == True) & (y_pred_i == False)).sum()\n",
    "    FP = ((y == False) & (y_pred_i == True)).sum()\n",
    "    return cost_1*FN + cost_2*FP\n",
    "\n",
    "# Calculate loss for 1000 evenly distributed thresholds\n",
    "thresholds = np.arange(0.0, 1.0, .001)\n",
    "losses = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_i = (logit_model.predict(X_with_intercept) > threshold)\n",
    "    loss = calculate_loss(y_pred_i, y)\n",
    "    losses.append(loss)\n",
    "\n",
    "print(losses)\n",
    "# Find the optimal threshold\n",
    "optimal_threshold = thresholds[np.argmin(losses)]\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "\n",
    "# Plot the loss with respect to the threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, losses, marker='o', markersize=2)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Loss (FN + FP)')\n",
    "plt.title('Loss with Respect to Threshold')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare\n",
      "0         0       3    male  22.0      1      0   7.2500\n",
      "1         1       1  female  38.0      1      0  71.2833\n",
      "2         1       3  female  26.0      0      0   7.9250\n",
      "3         1       1  female  35.0      1      0  53.1000\n",
      "4         0       3    male  35.0      0      0   8.0500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prob 2-a\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic = pd.read_csv('titanic-1.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(titanic.head())\n",
    "\n",
    "# Create a boxplot of Fare grouped by Pclass\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Pclass', y='Fare', data=titanic)\n",
    "plt.xlabel('Ticket Class')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Boxplot of Fare by Ticket Class')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Sex and Survived:\n",
      "Survived    0    1\n",
      "Sex               \n",
      "female     64  197\n",
      "male      360   93\n",
      "\n",
      "Confusion Matrix for Pclass and Survived:\n",
      "Survived    0    1\n",
      "Pclass            \n",
      "1          64  122\n",
      "2          90   83\n",
      "3         270   85\n"
     ]
    }
   ],
   "source": [
    "# Prob 2-b\n",
    "# Create a confusion matrix for Sex and Survived variables\n",
    "conf_matrix_sex_survived = pd.crosstab(titanic['Sex'], titanic['Survived'])\n",
    "\n",
    "# Print the confusion matrix for Sex and Survived\n",
    "print(\"Confusion Matrix for Sex and Survived:\")\n",
    "print(conf_matrix_sex_survived)\n",
    "\n",
    "# Create a confusion matrix for Pclass and Survived variables\n",
    "conf_matrix_pclass_survived = pd.crosstab(titanic['Pclass'], titanic['Survived'])\n",
    "\n",
    "# Print the confusion matrix for Pclass and Survived\n",
    "print(\"\\nConfusion Matrix for Pclass and Survived:\")\n",
    "print(conf_matrix_pclass_survived)\n",
    "\n",
    "# The lower the ticket price / fare, the less probable of surviving. Also women had a higher chance of surviving that men. Then Jack, who had a low ticket and was a men was fucked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      int64\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Fare        float64\n",
      "Pclass_2      int64\n",
      "Pclass_3      int64\n",
      "Sex_male      int64\n",
      "dtype: object\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  714\n",
      "Model:                            GLM   Df Residuals:                      706\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -317.89\n",
      "Date:                Fri, 22 Nov 2024   Deviance:                       635.78\n",
      "Time:                        00:07:01   Pearson chi2:                     749.\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.3690\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.1800      0.503      8.303      0.000       3.193       5.167\n",
      "Age           -0.0442      0.008     -5.343      0.000      -0.060      -0.028\n",
      "SibSp         -0.3768      0.127     -2.956      0.003      -0.627      -0.127\n",
      "Parch         -0.0613      0.123     -0.498      0.618      -0.302       0.180\n",
      "Fare           0.0020      0.003      0.797      0.425      -0.003       0.007\n",
      "Pclass_2      -1.2925      0.322     -4.017      0.000      -1.923      -0.662\n",
      "Pclass_3      -2.5011      0.339     -7.383      0.000      -3.165      -1.837\n",
      "Sex_male      -2.6375      0.220    -11.984      0.000      -3.069      -2.206\n",
      "==============================================================================\n",
      "          Odds Ratio\n",
      "Pclass_2    0.274573\n",
      "Pclass_3    0.081997\n"
     ]
    }
   ],
   "source": [
    "# 2-c\n",
    "# Transform Pclass into a factor (categorical) variable\n",
    "titanic_cat = titanic.copy()\n",
    "titanic_cat['Pclass'] = titanic_cat['Pclass'].astype('category')\n",
    "titanic_cat = pd.get_dummies(titanic_cat, drop_first=True)\n",
    "bool_columns = titanic_cat.select_dtypes(include='bool').columns\n",
    "titanic_cat[bool_columns] = titanic_cat[bool_columns].astype(int)\n",
    "\n",
    "# Verify the transformation\n",
    "print(titanic_cat.dtypes)\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X = titanic_cat.drop(columns=['Survived'])  # Predictor variables (all columns except 'Survived')\n",
    "y = titanic_cat['Survived']  # Response variable\n",
    "\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.GLM(y, X_with_intercept, family=sm.families.Binomial()).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "coefficients = logit_model.params\n",
    "pclass_coefficients = coefficients.filter(like=\"Pclass\")\n",
    "\n",
    "# Calculating odds ratios\n",
    "odds_ratios = np.exp(pclass_coefficients)\n",
    "\n",
    "# Formatting results for interpretation\n",
    "pclass_odds_ratios = odds_ratios.to_frame(name=\"Odds Ratio\")\n",
    "print(pclass_odds_ratios)\n",
    "\n",
    "# Interpretation of the Odds Ratios for Pclass\n",
    "# Pclass_2 (Odds Ratio = 0.275): Passengers in Pclass_2 have 0.275 times the odds of survival compared to those in the baseline class (Pclass_1). This means their odds of survival are reduced by approximately 72.5% relative to the baseline.\n",
    "# Pclass_3 (Odds Ratio = 0.082): Passengers in Pclass_3 have 0.082 times the odds of survival compared to those in the baseline class (Pclass_1). This indicates a significant reduction in survival odds by approximately 91.8% relative to the baseline.#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 535\n",
      "Testing set size: 179\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0           96           11\n",
      "Actual 1           19           53\n",
      "Sensitivity: 0.7361\n",
      "Specificity: 0.8972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Problem 2-d\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "# 4 Prepar X and Y# Split data\n",
    "titanic_shuffled = titanic.copy().sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "titanic_shuffled['Pclass'] = titanic_shuffled['Pclass'].astype('category')\n",
    "titanic_shuffled = pd.get_dummies(titanic_shuffled, drop_first=True)\n",
    "bool_columns = titanic_shuffled.select_dtypes(include='bool').columns\n",
    "titanic_shuffled[bool_columns] = titanic_shuffled[bool_columns].astype(int)\n",
    "X = titanic_shuffled.drop(columns=['Survived'])  # Predictor variables (all columns except 'Survived')\n",
    "y = titanic_shuffled['Survived']  # Response variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.75 * len(titanic_shuffled))\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Display the sizes of the training and testing sets\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_train_with_intercept = sm.add_constant(X_train)\n",
    "X_test_with_intercept = sm.add_constant(X_test)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.GLM(y_train, X_train_with_intercept, family=sm.families.Binomial()).fit()\n",
    "\n",
    "y_test_pred = (logit_model.predict(X_test_with_intercept) > 0.5)\n",
    "\n",
    "# Create a confusion matrix of your classification and the true survival status\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "# Print sensitivity and specificity\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fitting the model: module 'statsmodels.genmod.families' has no attribute 'Multinomial'\n"
     ]
    }
   ],
   "source": [
    "# 4A with Stats Model\n",
    "try:\n",
    "    mnlogit_model = sm.MNLogit(y_train_numeric, X_train_scaled_with_intercept).fit()\n",
    "    # Display the model summary\n",
    "    print(mnlogit_model.summary())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while fitting the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fitting the model: module 'statsmodels.genmod.families' has no attribute 'Multinomial'\n"
     ]
    }
   ],
   "source": [
    "# 4A with Stats Model\n",
    "try:\n",
    "    mnlogit_model = sm.MNLogit(y_train_numeric, X_train_scaled_with_intercept).fit()\n",
    "    # Display the model summary\n",
    "    print(mnlogit_model.summary())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while fitting the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4 import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob 4 explore data\n",
    "\n",
    "letters = pd.read_csv('letters-2.csv')\n",
    "print(letters.dtypes)\n",
    "print(letters.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(letters.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Prepar X and Y\n",
    "# Split data\n",
    "letters_shuffled = letters.copy().sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_size = int(0.75 * len(letters_shuffled))\n",
    "train_set = letters_shuffled[:train_size]\n",
    "test_set = letters_shuffled[train_size:]\n",
    "\n",
    "# Display the sizes of the training and testing sets\n",
    "print(f\"Training set size: {train_set.shape[0]}\")\n",
    "print(f\"Testing set size: {test_set.shape[0]}\")\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X_train = train_set.drop(columns=['lettr'])  # Predictor variables (all columns except 'lettr')\n",
    "y_train = train_set['lettr']  # Response variable\n",
    "y_train_numeric = y_train.astype('category').cat.codes  # Encode categorical target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled_with_intercept = sm.add_constant(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fitting the model: module 'statsmodels.genmod.families' has no attribute 'Multinomial'\n"
     ]
    }
   ],
   "source": [
    "# 4A with Stats Model\n",
    "try:\n",
    "    mnlogit_model = sm.MNLogit(y_train_numeric, X_train_scaled_with_intercept).fit()\n",
    "    # Display the model summary\n",
    "    print(mnlogit_model.summary())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while fitting the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a - SK learn fit model\n",
    "sk_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "sk_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "coefficients = sk_model.coef_  # Shape: (n_classes, n_features)\n",
    "intercepts = sk_model.intercept_  # Shape: (n_classes,)\n",
    "\n",
    "# Classes and shape details\n",
    "print(f\"Classes: {sk_model.classes_}\")\n",
    "print(f\"Number of features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"Number of classes: {len(sk_model.classes_)}\")\n",
    "\n",
    "# Coefficients\n",
    "print(\"Coefficients (one row per class):\")\n",
    "print(coefficients)\n",
    "\n",
    "# Intercepts\n",
    "print(\"Intercepts (one per class):\")\n",
    "print(intercepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b\n",
    "# Predict the letters for the training set\n",
    "train_pred = sk_model.predict(X_train_scaled)\n",
    "\n",
    "# Display the first few predictions\n",
    "print(train_pred[:10])\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=sk_model.classes_, columns=sk_model.classes_)\n",
    "\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Calculate classification accuracy by summing the diagonal elements and dividing by the total number of samples\n",
    "correct_classifications = np.trace(conf_matrix)  # Sum of diagonal elements\n",
    "total_classifications = np.sum(conf_matrix)  # Total number of samples\n",
    "accuracy_manual = correct_classifications / total_classifications\n",
    "\n",
    "print(f\"Classification Accuracy (manual calculation): {accuracy_manual:.4f}\")\n",
    "\n",
    "# Calculate classification accuracy using sklearn's accuracy_score for comparison\n",
    "accuracy_sklearn = accuracy_score(y_train, train_pred)\n",
    "print(f\"Classification Accuracy (sklearn): {accuracy_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4c\n",
    "# Define predictor variables and response variable\n",
    "X_test = test_set.drop(columns=['lettr'])  # Predictor variables (all columns except 'lettr')\n",
    "y_test = test_set['lettr']  # Response variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "# Predict the letters for the training set\n",
    "test_pred = sk_model.predict(X_test_scaled)\n",
    "\n",
    "# Display the first few predictions\n",
    "print(test_pred[:10])\n",
    "\n",
    "# Calculate classification accuracy using sklearn's accuracy_score for comparison\n",
    "accuracy_sklearn = accuracy_score(y_test, test_pred)\n",
    "print(f\"Classification Accuracy (sklearn) test: {accuracy_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4d\n",
    "\n",
    "# Prepare the full dataset\n",
    "full_set = letters.copy()\n",
    "\n",
    "# Display the sizes of the training and testing sets\n",
    "print(f\"Training set size: {full_set.shape[0]}\")\n",
    "print(f\"Testing set size: {full_set.shape[0]}\")\n",
    "\n",
    "# Define predictor variables and response variable\n",
    "X = full_set.drop(columns=['lettr'])  # Predictor variables (all columns except 'lettr')\n",
    "y = full_set['lettr']  # Response variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train a logistic regression model (multinomial)\n",
    "model_full = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "model_full.fit(X_scaled, y)\n",
    "\n",
    "# Read data and predict\n",
    "top_secret = pd.read_csv('topsecret-1.csv')\n",
    "\n",
    "# Ensure the top_secret dataset has the same columns and preprocess it\n",
    "X_top_secret = top_secret[X.columns]  # Ensure the same columns as X\n",
    "X_top_secret_scaled = scaler.transform(X_top_secret)  # Use the same scaler as training\n",
    "\n",
    "# Predict on the top_secret dataset\n",
    "pred = model_full.predict(X_top_secret_scaled)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Predictions for top_secret dataset:\")\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

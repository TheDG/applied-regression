{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "boo = pd.read_csv(\"boo.csv\")\n",
    "\n",
    "# Less than 1% of rows have one or more missing values; drop them\n",
    "print(f\"Original rows: {len(boo)}\")\n",
    "boo_clean = boo.dropna()\n",
    "print(f\"Cleaned rows: {len(boo_clean)}\")\n",
    "\n",
    "X = boo_clean[['x1', 'x2', 'x3', 'x4', 'x5', 'x6']]\n",
    "y = boo_clean['y']\n",
    "X_with_intercept = sm.add_constant(X)  # Add a constant term to the model\n",
    "\n",
    "model = sm.OLS(y, X_with_intercept).fit()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "boo_fillednas = boo.fillna(boo.mean())\n",
    "X_fillednas = boo_fillednas[['x1', 'x2', 'x3', 'x4', 'x5', 'x6']]\n",
    "y_fillednas = boo_fillednas['y']\n",
    "X_fillednas_with_intercept = sm.add_constant(X_fillednas)  # Add a cons tant term to the model\n",
    "\n",
    "model_fillednas = sm.OLS(y_fillednas, X_fillednas_with_intercept).fit()\n",
    "print(model_fillednas.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# Get studentized residuals\n",
    "influence = model.get_influence()\n",
    "studentized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "# Generate points for the standard normal distribution\n",
    "normdis_range = np.linspace(min(studentized_residuals), max(studentized_residuals), 100)\n",
    "normdis = norm.pdf(normdis_range, 0, 1)\n",
    "\n",
    "# Plot the standard normal density\n",
    "plt.hist(studentized_residuals,density=True, label='Histogram of Studentized Residuals', bins=15, edgecolor='black')\n",
    "plt.plot(normdis_range, normdis, 'r-', lw=2, label='Standard Normal Density')\n",
    "\n",
    "plt.xlabel('Studentized Residuals')\n",
    "plt.ylabel('Density')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "fitted_values = model.fittedvalues\n",
    "residuals = model.resid\n",
    "plt.scatter(fitted_values, residuals, s=3, color='black')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2 ----------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "def plot_diagnostics(results, X, y):\n",
    "    # Create influence instance\n",
    "    influence = OLSInfluence(results)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    axes[0, 0].scatter(results.fittedvalues, results.resid, edgecolors='k', facecolors='none')\n",
    "    axes[0, 0].set_xlabel('Fitted values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted')\n",
    "    # Add smoothed line of fit\n",
    "    smooth_resid = lowess(results.resid, results.fittedvalues)\n",
    "    axes[0, 0].plot(smooth_resid[:, 0], smooth_resid[:, 1], color='r', lw=2)\n",
    "    \n",
    "    # 2. Normal Q-Q\n",
    "    sm.qqplot(results.resid_pearson, line='45', fit=True, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Normal Q-Q')\n",
    "    \n",
    "    # 3. Scale-Location\n",
    "    standardized_resid = results.get_influence().resid_studentized_internal\n",
    "    axes[1, 0].scatter(results.fittedvalues, np.sqrt(np.abs(standardized_resid)), edgecolors='k', facecolors='none')\n",
    "    axes[1, 0].set_xlabel('Fitted values')\n",
    "    axes[1, 0].set_ylabel('$\\\\sqrt{|Standardized residuals|}$')\n",
    "    axes[1, 0].set_title('Scale-Location')\n",
    "    sqrt_abs_resid = np.sqrt(np.abs(standardized_resid))\n",
    "    smooth = lowess(sqrt_abs_resid, results.fittedvalues)\n",
    "    axes[1, 0].plot(smooth[:, 0], smooth[:, 1], color='r', lw=2)\n",
    "    \n",
    "     \n",
    "    # 4. Residuals vs Leverage\n",
    "    axes[1, 1].scatter(influence.hat_matrix_diag, results.resid_pearson, edgecolors='k', facecolors='none')\n",
    "    axes[1, 1].set_xlabel('Leverage')\n",
    "    axes[1, 1].set_ylabel('Standardized residuals')\n",
    "    axes[1, 1].set_title('Residuals vs Leverage')\n",
    "    axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "\n",
    "    # Add Cook's distance contours\n",
    "    cooksx = np.linspace(0.001, max(influence.hat_matrix_diag), 100)\n",
    "    p = len(results.params)\n",
    "    poscooks = np.sqrt((p * (1 - cooksx)) / cooksx)\n",
    "    negcooks = -np.sqrt((p * (1 - cooksx)) / cooksx)\n",
    "\n",
    "    axes[1, 1].plot(cooksx, poscooks, 'r--', lw=1)\n",
    "    axes[1, 1].plot(cooksx, negcooks, 'r--', lw=1)\n",
    "\n",
    "    # Add annotation for Cook's distance\n",
    "    axes[1, 1].annotate(\"Cook's distance\", xy=(max(cooksx), max(poscooks)), \n",
    "                        xytext=(0, 5), textcoords='offset points', \n",
    "                        ha='right', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "nutrition = pd.read_csv('nutrition.csv')\n",
    "# Display summary statistics\n",
    "summary = nutrition.describe()\n",
    "\n",
    "\n",
    "# Fit the SLR model using LinearRegression\n",
    "X = nutrition['age'] # Predictor variable\n",
    "y = nutrition['woh']  # Response variable\n",
    "# Add a constant to the predictor variable (intercept term)\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "X_with_intercept.rename(columns={'const': 'WOH_intercept'}, inplace=True)\n",
    "# Create and fit the model\n",
    "initial_model = sm.OLS(y, X_with_intercept).fit()\n",
    "\n",
    "plot_diagnostics(initial_model, X_with_intercept, y)\n",
    "\n",
    "# Create the new variable age^2\n",
    "nutrition['age2'] = nutrition['age'] ** 2\n",
    "# Define the new predictor variables including age and age^2\n",
    "X_new = nutrition[['age', 'age2']]\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_new_with_intercept = sm.add_constant(X_new)\n",
    "# Create and fit the MLR model using OLS\n",
    "model_new = sm.OLS(y, X_new_with_intercept).fit()\n",
    "plot_diagnostics(model_new, X_new_with_intercept, y)\n",
    "\n",
    "# Using interaction terms (GROUP)\n",
    "# nutrition is already sorted by age\n",
    "nutrition['group'] = [1 if i < 7 else 0 for i in range(len(nutrition))] # group starts at 0\n",
    "# Create interaction terms\n",
    "nutrition['age_group'] = nutrition['age'] * nutrition['group']\n",
    "# Define the new predictor variables including age, group, and the interaction term\n",
    "X_with_interaction = nutrition[['age', 'group', 'age_group']]\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_interaction_with_intercept = sm.add_constant(X_with_interaction)\n",
    "# Create and fit the interaction model using OLS\n",
    "model_interaction = sm.OLS(y, X_interaction_with_intercept).fit()\n",
    "# Call the function to plot the regression and residuals for the interaction model\n",
    "plot_diagnostics(model_interaction, X_interaction_with_intercept, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 3 -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data set for problem 3 & display rows\n",
    "cheese = pd.read_csv('cheese.csv')\n",
    "print(cheese.head())  # Display first few rows\n",
    "\n",
    "summary = cheese.describe() \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A \n",
    "# Define predictor and response variables\n",
    "display = cheese['disp']  # Predictor variable (in-store display)\n",
    "sales = cheese['vol']     # Response variable (sales volume)\n",
    "log_sales = np.log(sales) # Log-transformed sales volume\n",
    "\n",
    "# Convert display to a categorical variable\n",
    "display_category = display.astype('category')\n",
    "\n",
    "# Add a constant to the predictor variable (intercept term)\n",
    "X_with_intercept = sm.add_constant(display_category)\n",
    "X_with_intercept.rename(columns={'const': 'sales_intercept', 'disp': 'display_in_store'}, inplace=True)\n",
    "\n",
    "# Create and fit the model\n",
    "model = sm.OLS(log_sales, X_with_intercept).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "# Plot residuals to check for patterns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model.fittedvalues, model.resid)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Create a box plot to compare log sales for the two groups (with and without in-store displays)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=display, y=log_sales)\n",
    "plt.xlabel('In-Store Display (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Log Sales Volume')\n",
    "plt.title('Box Plot of Log Sales Volume by In-Store Display')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part b \n",
    "# Define predictor and response variables\n",
    "display = cheese['disp']  # Predictor variable (in-store display)\n",
    "sales = cheese['vol']     # Response variable (sales volume)\n",
    "ln_sales = np.log(sales) # Log-transformed sales volume\n",
    "price = cheese['price']\n",
    "ln_price = np.log(price) # Log-transformed price\n",
    "\n",
    "\n",
    "# Convert display to a categorical variable\n",
    "display_category = display.astype('category')\n",
    "price_display_interaction = display * ln_price\n",
    "\n",
    "# New predictor variables\n",
    "X = pd.DataFrame({\n",
    "    'ln_price': ln_price,\n",
    "    'display': display,\n",
    "    'price_display_interaction': price_display_interaction\n",
    "})\n",
    "\n",
    "# Add a constant to the predictor variables (intercept term)\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "\n",
    "# Create and fit the model\n",
    "model = sm.OLS(log_sales, X_with_intercept).fit()\n",
    "\n",
    "# Print the summary of the model to see the results\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
